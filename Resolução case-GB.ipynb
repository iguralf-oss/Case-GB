{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Case técnico - Analista de dados III - Igor Ralf da Silva",
   "id": "6d2e14b3ef748eb9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Seção 1 - SQL\n",
    "\n",
    "    Para iniciar a resolução do problema, é necessário entender como os dados estão dispostos dentro das tabelas e quais os possíveis problemas dentro da sua estrutura. Para garantir a solução adequada são necessárias algumas premissas:\n",
    "\n",
    "1. A tb_cpv_historico pode conter ou não dados de 2023, ou seja, para as tabelas **_tb_cpv_ecomm_linx_** e **_tb_cpv_ecomm_** serão usados apenas os dados de 2023\n",
    "2. Como entre as tabelas _**tb_cpv_ecomm_linx**_ e **_tb_cpv_ecomm_** não existem sobreposições, posso unir todos os dados das duas tabelas em apenas uma\n",
    "3. Dentro da tabela **_tb_cpv_ecomm_linx_** é necessário construir a formatação correta com o \"0\" antes do dado\n",
    "4. O CPV do combo é determinado pelo somatório do CPV de seus itens, logo, não posso extrair o valor final direto pela tabela **_tb_produto_skus_** por não saber o ‘input’ inicial desses dados, por tanto, os combos serão removidos dela\n",
    "5. Como COD_MATERIAL_FILHO é o código de cada produto do combo, logo, o somatório dos CPVs do COD_MATERIAL_FILHO será o CPV do COD_MATERIAL_PAI\n",
    "6. O formato dos campos é desconhecido (‘string’, integer, float), portanto, mesmo que a grafia seja, por exemplo, de booleano, posso estar a trabalhar com um campo em ‘string’"
   ],
   "id": "f1db816b719db362"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Para resolução do primeiro ponto ao terceiro ponto serão construídas as tabelas filtradas para 2023 e com os campos necessários alterados",
   "id": "7d67d71ac76759f5"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql1"
    }
   },
   "cell_type": "code",
   "source": [
    "%%sql\n",
    "SELECT COD_UN_NEGOCIO, CAST(COD_MATERIAL AS STRING) AS COD_MATERIAL, ANO, MIN(CPV)\n",
    "      FROM tb_cpv_ecomm\n",
    "      where CAST(ANO AS STRING) = \"2023\"\n",
    "      GROUP BY COD_MATERIAL, COD_UN_NEGOCIO, ANO, FLG_COMBO\n",
    "      UNION ALL\n",
    "      (SELECT\n",
    "        COD_UN_NEGOCIO,\n",
    "        CASE WHEN STARTS_WITH(CAST(COD_MATERIAL AS STRING), '0')\n",
    "        THEN CAST(COD_MATERIAL AS STRING) ELSE CONCAT('0', CAST(COD_MATERIAL AS STRING))\n",
    "        END AS COD_MATERIAL,\n",
    "        ANO, MIN(CPV)\n",
    "      FROM tb_cpv_ecomm_linx AS B\n",
    "      where CAST(ANO AS STRING) = \"2023\"\n",
    "      GROUP BY COD_MATERIAL, COD_UN_NEGOCIO, ANO, FLG_COMBO)\n"
   ],
   "id": "83b809a846c720cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Em seguida, é necessário construir a estrutura da tabela de **_tb_produto_skus_** de maneira filtrada para remover os combos e evitar um processamento excessivo",
   "id": "a4bb7d4d81d14540"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql2"
    }
   },
   "cell_type": "code",
   "source": [
    "%%sql\n",
    "  SELECT CAST(COD_MATERIAL AS STRING) AS COD_MATERIAL, COD_UN_NEGOCIO\n",
    "  FROM tb_produto_skus\n",
    "  where LOWER(CAST (flg_combo as STRING)) = ('false')"
   ],
   "id": "5ee79c7cb0dfc6fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Agora preciso criar uma tabela de histórico pegando apenas o minimo do cpv",
   "id": "a55bb7f19a020434"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql3"
    }
   },
   "cell_type": "code",
   "source": [
    "%%sql\n",
    "    SELECT COD_UN_NEGOCIO, CAST(COD_MATERIAL AS STRING) AS COD_MATERIAL, ANO, MIN(CPV)\n",
    "    FROM tb_cpv_historico\n",
    "    GROUP BY COD_MATERIAL, COD_UN_NEGOCIO, ANO, FLG_COMBO"
   ],
   "id": "1cbfbe3a463403f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Compilando os valores de CPV",
   "id": "669e0412a97a1aac"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql4"
    }
   },
   "cell_type": "code",
   "source": [
    "%%sql\n",
    "SELECT COALESCE(A.COD_UN_NEGOCIO, B.COD_UN_NEGOCIO) AS COD_UN_NEGOCIO,\n",
    "       COALESCE(A.COD_MATERIAL, B.COD_MATERIAL) AS COD_MATERIAL,\n",
    "       COALESCE(A.ANO, B.ANO) AS ANO,\n",
    "       LEAST(A.CPV, B.CPV) AS CPV\n",
    "    FROM tb_cpv_historico_ajust AS A\n",
    "    FULL JOIN tb_cpv_linx_ecomm as B\n",
    "    ON A.COD_UN_NEGOCIO = B.COD_UN_NEGOCIO\n",
    "    AND A.ANO = B.ANO\n",
    "    AND A.COD_MATERIAL = B.COD_MATERIAL\n"
   ],
   "id": "e7eac7727eb1d5ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Agora preciso agregar os valores de CPV para os produtos que são combo e para os que não são combo",
   "id": "405a02cd1694f320"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql5"
    }
   },
   "cell_type": "code",
   "source": [
    "%%sql\n",
    "--produtos_nao_combo\n",
    "SELECT A.COD_MATERIAL, A.COD_UN_NEGOCIO, B.CPV, 0 as FLG_COMBO, B.ANO\n",
    "FROM tb_produto_skus_filtrada as A\n",
    "\n",
    "\n",
    "INNER JOIN\n",
    "    CPV_COMP  AS B\n",
    "ON A.COD_UN_NEGOCIO = B.COD_UN_NEGOCIO\n",
    "AND A.COD_MATERIAL = B.COD_MATERIAL\n",
    "\n"
   ],
   "id": "48f52915607dd53f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql6"
    }
   },
   "cell_type": "code",
   "source": [
    "%%sql\n",
    "--produtos_combo as\n",
    "\n",
    "  SELECT A.COD_MATERIAL_PAI AS COD_MATERIAL, A.COD_UN_NEGOCIO, B.ANO,\n",
    "  SUM (B.CPV) AS CPV, 1 AS FLG_COMBO\n",
    "FROM tb_produto_sku_combo AS A\n",
    "INNER JOIN\n",
    "CPV_COMP as B\n",
    "ON A.COD_UN_NEGOCIO = B.COD_UN_NEGOCIO\n",
    "AND A.COD_MATERIAL_FILHO = B.COD_MATERIAL\n",
    "GROUP BY A.COD_MATERIAL_PAI, B.ANO, A.COD_UN_NEGOCIO\n",
    "\n"
   ],
   "id": "270d68aa62a71bf5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Agregando todo o código e usando uma estrutura de CTEs, obtemos o código a seguir:",
   "id": "f366da480a8f0f5a"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql7"
    }
   },
   "cell_type": "code",
   "source": [
    "%%sql\n",
    "WITH\n",
    "tb_cpv_linx_ecomm as\n",
    "    (\n",
    "      SELECT COD_UN_NEGOCIO, CAST(COD_MATERIAL AS STRING) AS COD_MATERIAL, ANO, MIN(CPV)\n",
    "      FROM tb_cpv_ecomm\n",
    "      where CAST(ANO AS STRING) = \"2023\"\n",
    "      GROUP BY COD_MATERIAL, COD_UN_NEGOCIO, ANO, FLG_COMBO\n",
    "      UNION ALL\n",
    "      (SELECT\n",
    "        COD_UN_NEGOCIO,\n",
    "        CASE WHEN STARTS_WITH(CAST(COD_MATERIAL AS STRING), '0')\n",
    "        THEN CAST(COD_MATERIAL AS STRING) ELSE CONCAT('0', CAST(COD_MATERIAL AS STRING))\n",
    "        END AS COD_MATERIAL,\n",
    "        ANO, MIN(CPV)\n",
    "      FROM tb_cpv_ecomm_linx AS B\n",
    "      where CAST(ANO AS STRING) = \"2023\"\n",
    "      GROUP BY COD_MATERIAL, COD_UN_NEGOCIO, ANO, FLG_COMBO)\n",
    "    ),\n",
    "\n",
    "\n",
    "tb_produto_skus_filtrada AS\n",
    "  (\n",
    "      SELECT CAST(COD_MATERIAL AS STRING) AS COD_MATERIAL, COD_UN_NEGOCIO\n",
    "      FROM tb_produto_skus\n",
    "      where LOWER(CAST (flg_combo as STRING)) = ('false')\n",
    "  ),\n",
    "\n",
    "\n",
    "tb_cpv_historico_ajust AS\n",
    "    (\n",
    "        SELECT COD_UN_NEGOCIO, CAST(COD_MATERIAL AS STRING) AS COD_MATERIAL, ANO, MIN(CPV)\n",
    "        FROM tb_cpv_historico\n",
    "        GROUP BY COD_MATERIAL, COD_UN_NEGOCIO, ANO, FLG_COMBO\n",
    "    ),\n",
    "\n",
    "\n",
    "CPV_COMP AS\n",
    "    (\n",
    "        SELECT COALESCE(A.COD_UN_NEGOCIO, B.COD_UN_NEGOCIO) AS COD_UN_NEGOCIO,\n",
    "        COALESCE(A.COD_MATERIAL, B.COD_MATERIAL) AS COD_MATERIAL,\n",
    "        COALESCE(A.ANO, B.ANO) AS ANO,\n",
    "        LEAST(A.CPV, B.CPV) AS CPV\n",
    "        FROM tb_cpv_historico_ajust AS A\n",
    "        FULL JOIN tb_cpv_linx_ecomm as B\n",
    "        ON A.COD_UN_NEGOCIO = B.COD_UN_NEGOCIO\n",
    "        AND A.ANO = B.ANO\n",
    "        AND A.COD_MATERIAL = B.COD_MATERIAL\n",
    "\n",
    "    ),\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "produtos_nao_combo as\n",
    "\n",
    "    (\n",
    "        SELECT A.COD_MATERIAL, A.COD_UN_NEGOCIO, B.CPV, 0 as FLG_COMBO, B.ANO\n",
    "        FROM tb_produto_skus_filtrada as A\n",
    "        INNER JOIN\n",
    "            CPV_COMP  AS B\n",
    "        ON A.COD_UN_NEGOCIO = B.COD_UN_NEGOCIO\n",
    "        AND A.COD_MATERIAL = B.COD_MATERIAL\n",
    "    ),\n",
    "\n",
    "produtos_combo as\n",
    "\n",
    "    (\n",
    "        SELECT A.COD_MATERIAL_PAI AS COD_MATERIAL, A.COD_UN_NEGOCIO, B.ANO,\n",
    "        SUM (B.CPV) AS CPV, 1 AS FLG_COMBO\n",
    "        FROM tb_produto_sku_combo AS A\n",
    "        INNER JOIN\n",
    "        CPV_COMP as B\n",
    "        ON A.COD_UN_NEGOCIO = B.COD_UN_NEGOCIO\n",
    "        AND A.COD_MATERIAL_FILHO = B.COD_MATERIAL\n",
    "        GROUP BY A.COD_MATERIAL_PAI, B.ANO, A.COD_UN_NEGOCIO\n",
    "    )\n",
    "\n",
    "\n",
    "SELECT\n",
    "  COD_MATERIAL,\n",
    "  COD_UN_NEGOCIO,\n",
    "  CPV,\n",
    "  ANO,\n",
    "  FLG_COMBO\n",
    "FROM\n",
    "  produtos_nao_combo\n",
    "UNION ALL\n",
    "SELECT\n",
    "  COD_MATERIAL,\n",
    "  COD_UN_NEGOCIO,\n",
    "  CPV,\n",
    "  ANO,\n",
    "  FLG_COMBO\n",
    "FROM\n",
    "  produtos_combo\n"
   ],
   "id": "92a78ecea1c7adba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Para a validação da tabela, além da satisfação das premissas antes adotadas seria necessário verificar se os valores de cpv estão devidamente preenchidos, se os códigos material estão na formatação correta, algumas validações como formato de exibição do ano seriam necessárias antes da implementação do modelo, e os formatos dos campos, a query apresentada minimiza o erro em alguns casos, como o campo de cod_material em _‘string’_, mas não para todos os campos, além disso, é necessário verificar o preenchimento do campo unidade de negócio, foi inserido um campo de combo para identificação apenas, mas seria importante para a tabela final a verificação de duplicidade.",
   "id": "cdc5784832348e11"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Seção 2 - Python + Análise de dados\n",
   "id": "931aad8ed2949257"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "    OBS.: O compilador usado foi o pycharm com uma alocação máxima de 8gb de memória, o que limita o uso de modelos mais rebuscados",
   "id": "f6e103fe239a65b9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "    Para iniciar a construção do modelo é necessário estudar a qualificação dos modelos, para isso, é necessário compreender os dados disponíveis:",
   "id": "94c6ebdeea3046c1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. É necessário um modelo que gere 3 clusteres finais\n",
    "2. Não há uma pré-classificação dos dados\n",
    "3. Os comentários podem conter erros de grafia, problemas de acentuação e outros elementos não textuais em seu corpo\n",
    "4. Não serão feitas alterações na tabela de comentários inicial manualmente\n",
    "5. O modelo será construído como uma versão inicial e serão sugeridas ao final melhorias a ele"
   ],
   "id": "31a65101847e6781"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Com base nas premissas adotadas, inicialmente, foram agregados os dados de review e vendas em um único arquivo para unificação da fonte de dados. Em seguida, foi iniciada a construção lógica do modelo:",
   "id": "3ddaa74f5c06455e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    O modelo não possui pré-classificação então é um modelo não supervisionado, com 3 clusters finais, usando uma linguagem natural em língua portuguesa, com esses fatos, existem 2 opções que foram testadas:\n",
    "\n",
    "1. Usar um modelo do zero, ou seja, construir as etapas de preprocessamento, em que seria necessário transformar as letras para minúsculas, selecionar os caracteres coerentes com a língua portuguesa e vetorizar esses dados. Um erro encontrado era de palavras sem significado específico, como conjunções, então foi usada a biblioteca _nltk_ para remover _stopwords_ incoerentes, um dicionário (_floresta_) para garantir a presença apenas de palavras existentes e o _spacy_ para seleção apenas de adjetivos. Contudo, a conversão não foi como esperado e esse modelo **foi descontinuado**.\n",
    "2. Esse segundo modelo foi o aplicado ao final, ele utiliza uma biblioteca chamada **BERT** que é uma rede neural de palavras que é sensível a coloquialismos e ironias na classificação, a própria biblioteca possui tratamento para stopwords, palavras incorretas, esse modelo faria a construção dos vetores.\n"
   ],
   "id": "51a7d383311b78f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    Contudo, o BERT por si só não classifica o texto, então foram avaliados diversos modelos, muitos deles sendo desclassificados por conta da nuance de 3 clusteres, inclusive os modelos mais usados com o BERT e BERTopic, o DBScan e o HDBScan, respectivamente. Foram testados os modelos de GMM, clusterização hierárquica, K-medoids, K-Median e K-Means. Sendo o K-Means o modelo escolhido.\n",
    "\n",
    "1. O K-Means é um modelo simples e bastante utilizado, não possui boa gestão de outliers, mas possui baixo custo de processamento\n",
    "2. Os modelos de GMM e K-Median não conseguiram convergir com o Slot de RAM alocado\n",
    "3. A clusterização hierárquica leva muito tempo de execução, o que pode não ser eficiente em dados que se alterem bastante ou bigdata\n",
    "4. O modelo de K-medoids apresentou uma composição de palavras mais dispersa que o K-means dificultando os insights\n"
   ],
   "id": "6df86e4c60d0a5a1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Por fim, as bibliotecas usadas foram:\n",
    "\n",
    "1. ntlk\n",
    "2. pandas\n",
    "3. numpy\n",
    "4. skcit-learn\n",
    "5. umap-learn\n",
    "6. sentence-transformers (bert)\n",
    "7. matplotlib\n",
    "8. seaborn\n",
    "9. nltk\n",
    "\n",
    "E para iniciar o código, vamos instalá-las:"
   ],
   "id": "8f3a4854f4d8541d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pip install pandas\n",
    "pip install numpy\n",
    "pip install scikit-learn\n",
    "pip install umap-learn\n",
    "pip install sentence-transformers\n",
    "pip install matplotlib\n",
    "pip install seaborn\n",
    "pip install nltk"
   ],
   "id": "d496c20594d0e226"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Após a instalação no terminal das bibliotecas, o código será o seguinte:",
   "id": "bf74a59fe3ef3b28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import silhouette_score\n",
    "from umap import UMAP\n",
    "from sklearn.cluster import KMeans\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Baixar as stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words_pt = set(stopwords.words('portuguese'))\n",
    "stop_words_pt.discard('não')\n",
    "stop_words_pt.discard('mais')\n",
    "stop_words_pt.discard('muito')\n",
    "\n",
    "'''logica de importação e conversão em dataframe,\n",
    "a coluna de cod_material equivale ao valor da coluna de cod_produto e será renomeada para melhor coerência no join'''\n",
    "\n",
    "df_reviews = pd.read_csv('reviews.csv')\n",
    "df_vendas = pd.read_csv('vendas.csv')\n",
    "df_vendas_ajuste = df_vendas.rename(columns={'COD_MATERIAL': 'COD_PRODUTO'})\n",
    "df_comp = pd.merge(df_reviews, df_vendas_ajuste, on=['COD_PEDIDO', 'COD_PRODUTO'], how='left')\n",
    "df = pd.DataFrame(df_comp)\n",
    "\n",
    "#criar o campo de ano com mês e remover as outras informações\n",
    "df['DT_HR_CRIACAO'] = pd.to_datetime(df['DT_HR_CRIACAO'], errors='coerce')\n",
    "df['ANO_MES'] = df['DT_HR_CRIACAO'].dt.to_period('M')\n",
    "\n",
    "#Vou agrupar por cod_produto e por mês, então preciso remover do dataframe os valores nulos para cod_produto\n",
    "df.dropna(subset=['COD_PRODUTO', 'DT_HR_CRIACAO', 'MSG_AVALIACAO'], inplace=True)\n",
    "df['COD_PRODUTO'] = df['COD_PRODUTO'].astype(int)\n",
    "\n",
    "df['cluster_kmeans'] = np.nan #definir o valor inicial do \"cluster\" como uma coluna sem valores\n",
    "\n",
    "groups = df.groupby(['COD_PRODUTO', 'ANO_MES'])\n",
    "\n",
    "embedding_model_name = \"neuralmind/bert-base-portuguese-cased\"\n",
    "bert_model = SentenceTransformer(embedding_model_name)\n",
    "\n",
    "#foram testados diversos neighbors e n_components para melhor conversão\n",
    "\n",
    "umap_model = UMAP(n_neighbors=15, n_components=3, min_dist=0.0, metric='cosine', random_state=42)\n",
    "\n",
    "kmeans_model = KMeans(n_clusters=3, n_init=50, random_state=42) #poucas inicializações para um modelo inicial\n",
    "\n",
    "lista_silhuetas=[]\n",
    "lista_contagem_clusters=[]\n",
    "\n",
    "for (COD_PRODUTO, ANO_MES), df_group in groups:\n",
    "\n",
    "    textos_para_analise = [str(t) for t in df_group['MSG_AVALIACAO'].tolist()]\n",
    "\n",
    "    document_embeddings = bert_model.encode(textos_para_analise)\n",
    "\n",
    "    reduced_embeddings = umap_model.fit_transform(document_embeddings)\n",
    "\n",
    "    kmeans_model.fit(reduced_embeddings)\n",
    "    clusters = kmeans_model.predict(reduced_embeddings)\n",
    "\n",
    "    print(f\"Produto e mês: {COD_PRODUTO} e {ANO_MES}\")\n",
    "\n",
    "    contagem_clusters = pd.Series(clusters).value_counts().to_dict()\n",
    "    print(f\"\\nPopulação dos clusters: {contagem_clusters}\")\n",
    "\n",
    "\n",
    "    lista_contagem_clusters.append({'COD_PRODUTO': COD_PRODUTO, 'ANO_MES': ANO_MES,\n",
    "                                    'contagem_clusters': contagem_clusters\n",
    "    })\n",
    "\n",
    "\n",
    "    silhueta = silhouette_score(reduced_embeddings, clusters)\n",
    "    print(f\"Coeficiente de Silhueta: {silhueta:.2f}\\n\")\n",
    "    lista_silhuetas.append({'COD_PRODUTO': COD_PRODUTO, 'ANO_MES': str(ANO_MES),\n",
    "                            'Silhueta': silhueta\n",
    "                            })\n",
    "\n",
    "#Aqui o código, propriamente dito, já foi executado e daqui pra frente existirão regras de export e visualização\n",
    "\n",
    "    df.loc[df_group.index, 'cluster_kmeans'] = clusters\n",
    "\n",
    "    vectorizer = TfidfVectorizer(encoding=\"utf-8\", max_features=30, stop_words=list(stop_words_pt), ngram_range=(2, 3))\n",
    "    x_tfidf = vectorizer.fit_transform(df_group['MSG_AVALIACAO'])\n",
    "\n",
    "#foram vetorizadas as palavras para conseguirmos visualizá-las matricialmente, o tfidvectorizer foi algo usado no modelo descontinuado\n",
    "\n",
    "    top_words_data = []\n",
    "\n",
    "    for c in np.unique(clusters):\n",
    "        indice = np.where(clusters == c)[0]\n",
    "        tfidf = x_tfidf[indice]\n",
    "\n",
    "        mean_tfidf = np.array(tfidf.mean(axis=0))\n",
    "\n",
    "        top_indices = mean_tfidf.argsort()[-10:][::-1]\n",
    "        top_words = [vectorizer.get_feature_names_out()[i] for i in top_indices]\n",
    "\n",
    "        top_words_data.append({'cluster': c, 'top_words': top_words})\n",
    "        top_words_list = [str(word) for word in top_words]\n",
    "        print(f\"  Cluster {c}: {', '.join(top_words_list)}\")\n",
    "\n",
    "    df_top_words = pd.DataFrame(top_words_data)\n",
    "    df_top_words.to_csv(f'palavras_chave_p{COD_PRODUTO}_m{ANO_MES}.csv', index=False)\n",
    "\n",
    "    if 'ESTADO_AVALIADOR' in df_group.columns and not df_group['ESTADO_AVALIADOR'].isnull().all():\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.countplot(data=df, x='ESTADO_AVALIADOR', hue='cluster_kmeans')\n",
    "        plt.title(f'Distribuição de Clusters por Estado para o Produto {COD_PRODUTO} ({ANO_MES})')\n",
    "        plt.xlabel('Estado do Avaliador')\n",
    "        plt.ylabel('Contagem de Avaliações')\n",
    "        plt.legend(title='Cluster')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'clusters_estado_p{COD_PRODUTO}_m{ANO_MES}.png')\n",
    "        plt.close()\n",
    "\n",
    "    if 'DES_CANAL_VENDA_FINAL' in df_group.columns and not df_group['DES_CANAL_VENDA_FINAL'].isnull().all():\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.countplot(data=df, x='DES_CANAL_VENDA_FINAL', hue='cluster_kmeans')\n",
    "        plt.title(f'Distribuição de Clusters por Canal de Venda para o Produto {COD_PRODUTO} ({ANO_MES})')\n",
    "        plt.xlabel('Canal de Venda')\n",
    "        plt.ylabel('Contagem de Avaliações')\n",
    "        plt.legend(title='Cluster')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'clusters_canal_venda_p{COD_PRODUTO}_m{ANO_MES}.png')\n",
    "        plt.close()\n",
    "\n",
    "if lista_silhuetas:\n",
    "    df_silhuetas = pd.DataFrame(lista_silhuetas)\n",
    "    df_silhuetas.to_csv('silhueta_kmeans_bert_mes_produto.csv', index=False)\n",
    "\n",
    "if lista_contagem_clusters:\n",
    "    df_contagem = pd.DataFrame(lista_contagem_clusters)\n",
    "    df_contagem.to_csv('contagem_kmeans_bert_mes_produto.csv', index=False)\n",
    "\n",
    "df_final = df[['COD_PRODUTO', 'ANO_MES', 'MSG_AVALIACAO', 'cluster_kmeans', 'ESTADO_AVALIADOR', 'DES_CANAL_VENDA_FINAL', 'FLG_PRESENTE']]\n",
    "df_final.to_csv('compiladofinal_kmeans_bert_mes_produto.csv', index=False)\n",
    "\n",
    "#Específico para presentes\n",
    "\n",
    "if 'FLG_PRESENTE' in df.columns and not df['FLG_PRESENTE'].isnull().all():\n",
    "    for prod_id in df['COD_PRODUTO'].unique():\n",
    "        df_prod = df[df['COD_PRODUTO'] == prod_id]\n",
    "\n",
    "        if not df_prod.empty:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            sns.countplot(data=df_prod, x='cluster_kmeans', hue='FLG_PRESENTE')\n",
    "            plt.title(f'População de Clusters e Distribuição de Presente para o Produto {prod_id}')\n",
    "            plt.xlabel('Cluster')\n",
    "            plt.ylabel('Contagem de Avaliações')\n",
    "            plt.legend(title='Presente (FLG_PRESENTE)')\n",
    "            plt.xticks(rotation=0)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'clusters_flg_presente_p{prod_id}.png')\n",
    "            plt.close()\n",
    "\n",
    "df_produto_333 = df_final[df_final['COD_PRODUTO'] == 333].copy()\n",
    "df_produto_333 = df_produto_333.sort_values(by='cluster_kmeans')\n",
    "df_produto_333.to_csv('compilado_produto_333.csv', index=False)"
   ],
   "id": "9b3f5f643c9c602e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Sugestões ao modelo:\n",
    "\n",
    "1. Após a execução do código, atribuir os parâmetros negativo, positivo e neutro ao modelo e, reinserir os dados num modelo de aprendizagem supervisionada\n",
    "2. Pré-categorizar um grupo de dados para aumentar a assertividade e substituir o método por um modelo supervisionado\n",
    "3. Determinar um"
   ],
   "id": "7e16c8e46183"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Perguntas:\n",
    "1) Sabendo que o produto 333 foi lançado em 02/2025, como pode ser explicada a\n",
    "mudança de comportamento no sentimento das avaliações entre os meses 02, 03 e\n",
    "04?\n",
    "\n",
    "    R. No geral, para os 3 meses, o produto possui diversos comentários sobre a eficácia, nos dois primeiros meses a silhueta foi menor e todos os ‘clusters’ se assemelhavam mais, sendo que o principal argumento era sobre a baixa remoção de pelos. Após esse mês, surgiram palavras que apontavam para casos em que funcionava e em que não, com alguns comentários bem positivos e outros negativos, no terceiro e quarto meses as palavras sobre o cheiro aumentaram e começaram a se formar opiniões divididas. Basicamente, no primeiro mês foram coletadas mais opiniões e a eficácia do produto foi bem questionada, em seguida, algumas pessoas já estavam cientes do uso do produto e começaram a ter resultados, enquanto outras não, ao final, as opiniões dividiram, mas pontos como cheiro e eficácia continuam em alta, exigindo um olhar mais cuidadoso\n",
    "\n",
    "2) Entre os produtos 111 e 222, algum deles é mais indicado para uma campanha de\n",
    "incentivo a compras para presentear? Por quê?\n",
    "\n",
    "    R. O produto 111, ele apresentou mais análises positivas, além disso, o produto 222 apresentou críticas quanto a embalagem e logística, o que é crucial para presentear, o produto 222 apresentou uma queda significativa nas compras no mês 04, o que pode ter sido justificado pelas críticas de logística e embalagem, o que faz o produto 111 tornar-se mais relevante, mesmo com menor número de avaliações\n",
    "\n",
    "3) Faça uma análise exploratória dos dados. Existem outros insights que você acha\n",
    "relevante de serem compartilhados?\n",
    "\n",
    "    R. Foi feita uma análise da distribuição por estado de cada um dos produtos e os seus ‘clusters’, revelando uma alta concentração em SP, MG e RJ, além disso, a maioria das avaliações é realizada via ‘app’, a composição das palavras chave, no geral, revelam um sentimento mais positivo que negativo em relação aos produtos"
   ],
   "id": "6232d347b08ecedc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
